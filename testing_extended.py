import redis
import logging
import json
import datetime
import re
import requests
import pandas as pd
from bs4 import BeautifulSoup as bs
from textblob import TextBlob as tb
import urllib
from selenium import webdriver
from time import sleep
import threading
from random import randint

url_patern = 'http://tappedout.net/mtg-decks'
# generated by test.py ()
df = pd.read_csv('commander_deck_names.csv')
test = ['/the-notion-is-elemental-my-dear-watson/']

def parser_decks(deck_name, drive, url = url_patern):
    url_comm = url+deck_name

    drive.get(url_comm)
    request = drive.execute_script("window.scrollTo(0,document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;")
    sleep(randint(6,8))# currently set to 4 secs(rough estimate 3600 secs.(~3h)) will need paraleles...
    returns = bs(drive.page_source, 'html.parser')

    temp1 = []
    temp = returns.findAll('ul')
    for i in temp:
        temp1.append(i.findAll('a', href = re.compile('/mtg-card/')))


    # results =  com_result + deck_result
    fresults = []
    comm = []
    for i in temp1:
        set_ = clean(i)
        if set_ == None:
            comm.extend(clean(i, comm_trig = True))
        else:
            fresults.extend(clean(i))
        

    res_dict = {str(comm) : [fresults]}
    return  res_dict

# add following three to tool_belt.py hella usefull in future ventures....
def clean(t_list,comm_trig = False):# cleaning up the name html.
    list_=[]
    command =[]
    for i in t_list:
        try:
            if comm_trig == False: 
                list_.append(i.get('data-name'))#.find('a', attr = 'data-name'))
            else:
                list_.append(i.get('href'))
        except: # need to come p with conditional to define the commander..
            #command.append(i.get('href'))
            print(None)
    return list_ 
    
def strip_ (text_):# used in the above .
    step1 = re.sub('<a href=/mtg-card/"','',text_)
    step1 = re.sub('"','',step1)
    step2 = step1.split()
    step3 = step2[0]
    return step3

class spider_Thread(threading.Thread):
    def __init__(self, com_names):
        threading.Thread.__init__(self) 
        self.com_names = com_names
        self.driver = webdriver.Firefox(executable_path=r'/home/ed/Documents/gecko/geckodriver-v0.26.0-linux64/geckodriver')
        self.list_ = []

    def run(self):
        # driver = webdriver.Firefox(executable_path=r'/home/ed/Documents/gecko/geckodriver-v0.26.0-linux64/geckodriver')
        for i in self.com_names:
            temp = parser_decks(i, self.driver)
            self.list_.append(temp)
        list1 = self.list_ 
        self.driver.quit()
        return list1




test_tread = spider_Thread(test)
result1 = test_tread.run()
print(len(result1[0]), result1)
# /the-notion-is-elemental-my-dear-watson/